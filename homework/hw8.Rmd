---
title: "Homework #8"
author: "**Your Name Here**"
date: "Due: Tue Nov 03 | 1:55pm"
output: 
  html_document:
  # html_notebook:
    df_print: default  # set default format for table output
---

**SYS 6018 | Fall 2020 | University of Virginia **

*******************************************

<!--- Below are global settings for knitr. You can override any of them by adding the changes to individual chunks --->

```{r global_options, include=FALSE}
knitr::opts_chunk$set(error=TRUE,        # Keep compiling upon error
                      collapse=FALSE,    # collapse by default
                      echo=TRUE,         # echo code by default
                      comment = "#>",    # change comment character
                      fig.width = 5,     # set figure width
                      fig.align = "center",# set figure position
                      out.width = "49%", # set width of displayed images
                      warning=TRUE,      # show R warnings
                      message=TRUE)      # show R messages
options(dplyr.summarise.inform = FALSE)  # ignore message about group structure
```

<!--- Solution Region --->
```{css solution-region, echo=FALSE}
.solution {
  background-color: #232D4B10;
  border-style: solid;
  border-color: #232D4B;
  padding: .5em;
  margin: 20px
}
```


<!--- Load Required R packages here --->
```{r packages, include=FALSE}
#- Better table printing
library(kableExtra) # https://haozhu233.github.io/kableExtra/awesome_table_in_html.html
format_table <- function(x, nmax=10) {
  kable(x) %>% 
    kable_styling(full_width = FALSE, font_size=11, position = "left") %>% 
    {if(nrow(x) > nmax) scroll_box(., width = "100%", height = "200px") else .}
}
#- useful functions
digits <- function(x, k=2) format(round(x, k), nsmall=k)
#- data directory
data.dir = 'https://mdporter.github.io/SYS6018/data/'
#- required functions here
library(randomForest)
library(tidyverse)
```




### Problem 8: Kaggle 

We have officially ended our coverage of supervised learning. Let's cap it off with a Kaggle contest. 

You are to make at least one official entry in the [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview) Kaggle contest. 

- You will need to register in Kaggle (its free)
- Read the details of the contest. Understand the data and evaluation function.
- Make at least one submission
- If you get a score on the public leaderboard of $<0.50$, you receive full credit, otherwise, you'll lose 10 points. 
    - I'll allow [teaming](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/team) to achieve the score, but only if everyone on the team produces a model that is used to generate the final submission (e.g., stacking or model averaging)
- Submit your code on collab
- Report your kaggle name (or team name) so we can ensure you had a valid submission. 
- Top 5 scores get 2 bonus points
    - Teams will split their bonus points among team members


Note: Check out the [Kaggle notebooks](https://www.kaggle.com/docs/notebooks) which let you make submissions directly from the notebook. Its very similar to using Rivanna's OnDemand in that you can make a RMarkdown/Jupyter notebook or R/Python scrips that run on the cloud. Free CPU (4 cores, 16GB RAM) - amazing! Let your laptops cool off after all their hard work this semester. 



